"""
@input  .env é…ç½®ã€è±†åŒ…ç½‘é¡µ
@output Obsidian ç¬”è®°/ä»»åŠ¡æ–‡ä»¶
@pos    æ ¸å¿ƒç›‘æ§æœåŠ¡ï¼Œç›‘å¬è±†åŒ…èŠå¤©å¹¶å†™å…¥ Obsidian

è‡ªæŒ‡å£°æ˜ï¼šæ›´æ–°æ­¤æ–‡ä»¶æ—¶åŒæ­¥æ›´æ–°æ ¹ç›®å½• _INDEX.md
"""

import asyncio
import atexit
import hashlib
import json
import logging
import os
import re
import sqlite3
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Any

import aiofiles
from dotenv import load_dotenv
from playwright.async_api import async_playwright, Browser, Page, BrowserContext
from pydantic import ConfigDict, Field, field_validator
from pydantic_settings import BaseSettings

# èœå•æ å›¾æ ‡å’Œç³»ç»Ÿé€šçŸ¥
import pystray
from PIL import Image, ImageDraw
from plyer import notification

# ========== æ—¥å¿—é…ç½® ==========
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
    level=logging.DEBUG
)
logger = logging.getLogger(__name__)

# ========== é…ç½®ç®¡ç† ==========
class Settings(BaseSettings):
    """é…ç½®ç®¡ç†ç±»ï¼Œä½¿ç”¨ pydantic è¿›è¡ŒéªŒè¯"""
    OBSIDIAN_VAULT: str = ""
    NOTES_DIR: str = "Inbox/Voice Notes"
    TASKS_DIR: str = "Tasks"
    POLL_INTERVAL: int = Field(10, ge=1, le=300, description="è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰")
    SMART_POLLING: bool = Field(True, description="æ™ºèƒ½è½®è¯¢ï¼šæ´»è·ƒæ—¶å¿«é€Ÿï¼Œç©ºé—²æ—¶æ…¢é€Ÿ")
    FAST_POLL_INTERVAL: int = Field(5, ge=1, le=60, description="æ´»è·ƒæ—¶è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰")
    SLOW_POLL_INTERVAL: int = Field(30, ge=10, le=300, description="ç©ºé—²æ—¶è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰")
    CHAT_URL: str = "https://www.doubao.com/chat/624642496948226"
    DB_PATH: str = "data/processed.sqlite"
    STATE_PATH: str = "storage_state.json"
    DEBUG: bool = False
    HEADFUL: bool = True
    DEDUP_HOURS: int = Field(36, ge=1, le=168, description="å»é‡æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰")
    KEYWORD_NOTE: str = "è®°ç¬”è®°"
    KEYWORD_TASK: str = "è®°ä»»åŠ¡"

    model_config = ConfigDict(
        env_file=".env",
        env_file_encoding="utf-8"
    )


# åŠ è½½é…ç½®
load_dotenv()
settings = Settings()
VAULT = Path(settings.OBSIDIAN_VAULT).expanduser().resolve()
NOTES_DIR = settings.NOTES_DIR
TASKS_DIR = settings.TASKS_DIR
POLL_INTERVAL = settings.POLL_INTERVAL
CHAT_URL = settings.CHAT_URL
DB_PATH = Path(settings.DB_PATH)
STATE_PATH = Path(settings.STATE_PATH)
DEBUG = settings.DEBUG
HEADFUL = settings.HEADFUL
DEDUP_HOURS = settings.DEDUP_HOURS
KEYWORD_NOTE = settings.KEYWORD_NOTE
KEYWORD_TASK = settings.KEYWORD_TASK

# è®¾ç½®æ—¥å¿—çº§åˆ«
if not DEBUG:
    logger.setLevel(logging.INFO)

# ========== æ—¥å¿—é¢‘ç‡æ§åˆ¶ ==========
_log_counters = {}
_log_last_time = {}

def should_log_debug(key: str, interval_seconds: int = 30) -> bool:
    """æ§åˆ¶è°ƒè¯•æ—¥å¿—é¢‘ç‡ï¼Œé¿å…æ—¥å¿—åˆ·å±"""
    if not DEBUG:
        return False

    current_time = time.time()
    last_time = _log_last_time.get(key, 0)

    if current_time - last_time >= interval_seconds:
        _log_last_time[key] = current_time
        # æ˜¾ç¤ºç´¯è®¡æ¬¡æ•°
        count = _log_counters.get(key, 0)
        if count > 0:
            logger.debug(f"[{key}] (è¿‡å»{interval_seconds}ç§’å†…é‡å¤{count}æ¬¡)")
        _log_counters[key] = 0
        return True
    else:
        _log_counters[key] = _log_counters.get(key, 0) + 1
        return False

# ========== æ­£åˆ™é¢„ç¼–è¯‘ ==========
def build_cmd_regex() -> re.Pattern[str]:
    """æ ¹æ®é…ç½®çš„å…³é”®è¯æ„å»ºè§¦å‘æ­£åˆ™ï¼Œå®¹å¿"è±†åŒ…è±†åŒ…"å‰ç¼€å’Œè¯­éŸ³è¯†åˆ«é—®é¢˜"""
    # åŸºç¡€å…³é”®è¯
    kw_note = re.escape(KEYWORD_NOTE)
    kw_task = re.escape(KEYWORD_TASK)

    # è¯­éŸ³è¯†åˆ«å¯èƒ½çš„å˜ä½“
    note_variants = [
        kw_note,           # è®°ç¬”è®°
        "ç¬”è®°",            # è®°å­—ä¸¢å¤±
        "å‡ ç¬”è®°", "åŠç¬”è®°", "å³ç¬”è®°", "å¯„ç¬”è®°",  # åŒéŸ³å­—/è¿‘éŸ³å­—
        "è®°ä¸ªç¬”è®°", "è®°ä¸€ä¸‹ç¬”è®°", "è®°å½•ç¬”è®°", "è®°1ä¸ªç¬”è®°", "è®°ä¸€ä¸ªç¬”è®°",  # å£è¯­åŒ–+æ•°å­—
        "å¸®æˆ‘è®°ç¬”è®°", "å¸®æˆ‘è®°ä¸ªç¬”è®°", "å¸®æˆ‘è®°ä¸€ä¸‹ç¬”è®°",  # æ›´å£è¯­åŒ–
        "è®°è®°ç¬”è®°", "ç¬”ç¬”è®°",  # é‡å¤å­—ç¬¦
        "è®°æ¯”è®°",  # æ–¹è¨€å˜ä½“
    ]

    task_variants = [
        kw_task,           # è®°ä»»åŠ¡
        "ä»»åŠ¡",            # è®°å­—ä¸¢å¤±
        "å‡ ä»»åŠ¡", "åŠä»»åŠ¡", "å³ä»»åŠ¡", "å¯„ä»»åŠ¡",  # åŒéŸ³å­—/è¿‘éŸ³å­—
        "è®°ä¸ªä»»åŠ¡", "è®°ä¸€ä¸‹ä»»åŠ¡", "è®°å½•ä»»åŠ¡", "è®°1ä¸ªä»»åŠ¡", "è®°ä¸€ä¸ªä»»åŠ¡",  # å£è¯­åŒ–+æ•°å­—
        "æ·»åŠ ä»»åŠ¡", "æ–°å¢ä»»åŠ¡", "åˆ›å»ºä»»åŠ¡",  # åŒä¹‰è¯
        "å¸®æˆ‘è®°ä»»åŠ¡", "å¸®æˆ‘è®°ä¸ªä»»åŠ¡", "å¸®æˆ‘æ·»åŠ ä»»åŠ¡", "å¸®æˆ‘è®°ä¸€ä¸‹ä»»åŠ¡",  # æ›´å£è¯­åŒ–
        "è®°è®°ä»»åŠ¡", "ä»»ä»»åŠ¡",  # é‡å¤å­—ç¬¦
        "äººåŠ¡", "è®¤åŠ¡", "ä»åŠ¡",  # æ–¹è¨€/è¿‘éŸ³å˜ä½“
    ]

    # æ„å»ºæ­£åˆ™æ¨¡å¼
    note_pattern = "|".join(re.escape(v) for v in note_variants)
    task_pattern = "|".join(re.escape(v) for v in task_variants)

    # æ›´å®½æ¾çš„åˆ†éš”ç¬¦åŒ¹é…ï¼ŒåŒ…æ‹¬è¯­æ°”è¯å’Œå¡«å……è¯
    # æ”¯æŒï¼šå—¯ã€é‚£ä¸ªã€OKç­‰å¸¸è§è¯­æ°”è¯
    filler_words = r"(?:å—¯[ï¼Œ,\s]*|é‚£ä¸ª[ï¼Œ,\s]*|OK[ï¼Œ,\s]*|å¥½çš„[ï¼Œ,\s]*|å‘ƒ[ï¼Œ,\s]*)?"

    return re.compile(rf"^\s*{filler_words}(?:è±†åŒ…è±†åŒ…[ï¼Œ,:ï¼šã€‚\s]*)?{filler_words}(?:å¸®æˆ‘\s*)?({note_pattern}|{task_pattern})(?:[ï¼Œ,:ï¼šã€‚\så§å‘¢å•Š]*)?(.+)$", re.IGNORECASE)

CMD_RE = build_cmd_regex()

def normalize_matched_keyword(matched_keyword: str) -> str:
    """å°†åŒ¹é…åˆ°çš„å…³é”®è¯å˜ä½“æ ‡å‡†åŒ–ä¸ºåŸºç¡€å…³é”®è¯"""
    matched_lower = matched_keyword.lower().strip()

    # ç¬”è®°ç›¸å…³çš„æ‰€æœ‰å˜ä½“
    note_variants = [
        KEYWORD_NOTE.lower(), "ç¬”è®°", "å‡ ç¬”è®°", "åŠç¬”è®°", "å³ç¬”è®°", "å¯„ç¬”è®°",
        "è®°ä¸ªç¬”è®°", "è®°ä¸€ä¸‹ç¬”è®°", "è®°å½•ç¬”è®°", "è®°1ä¸ªç¬”è®°", "è®°ä¸€ä¸ªç¬”è®°",
        "å¸®æˆ‘è®°ç¬”è®°", "å¸®æˆ‘è®°ä¸ªç¬”è®°", "å¸®æˆ‘è®°ä¸€ä¸‹ç¬”è®°",
        "è®°è®°ç¬”è®°", "ç¬”ç¬”è®°", "è®°æ¯”è®°"
    ]

    # ä»»åŠ¡ç›¸å…³çš„æ‰€æœ‰å˜ä½“
    task_variants = [
        KEYWORD_TASK.lower(), "ä»»åŠ¡", "å‡ ä»»åŠ¡", "åŠä»»åŠ¡", "å³ä»»åŠ¡", "å¯„ä»»åŠ¡",
        "è®°ä¸ªä»»åŠ¡", "è®°ä¸€ä¸‹ä»»åŠ¡", "è®°å½•ä»»åŠ¡", "è®°1ä¸ªä»»åŠ¡", "è®°ä¸€ä¸ªä»»åŠ¡",
        "æ·»åŠ ä»»åŠ¡", "æ–°å¢ä»»åŠ¡", "åˆ›å»ºä»»åŠ¡",
        "å¸®æˆ‘è®°ä»»åŠ¡", "å¸®æˆ‘è®°ä¸ªä»»åŠ¡", "å¸®æˆ‘æ·»åŠ ä»»åŠ¡", "å¸®æˆ‘è®°ä¸€ä¸‹ä»»åŠ¡",
        "è®°è®°ä»»åŠ¡", "ä»»ä»»åŠ¡", "äººåŠ¡", "è®¤åŠ¡", "ä»åŠ¡"
    ]

    if matched_lower in note_variants:
        return KEYWORD_NOTE
    elif matched_lower in task_variants:
        return KEYWORD_TASK
    else:
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›åŸå§‹å€¼ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä½œä¸ºåå¤‡ï¼‰
        return matched_keyword

# é¢„ç¼–è¯‘å½’ä¸€åŒ–æ­£åˆ™
NORMALIZE_NOTE_RE = re.compile(
    rf"^(è±†åŒ…è±†åŒ…[ï¼Œ,:ï¼š\s]*)?{re.escape(KEYWORD_NOTE)}[ï¼Œ,:ï¼š\s]*{re.escape(KEYWORD_NOTE)}[ï¼Œ,:ï¼š\s]*"
)
NORMALIZE_TASK_RE = re.compile(
    rf"^(è±†åŒ…è±†åŒ…[ï¼Œ,:ï¼š\s]*)?{re.escape(KEYWORD_TASK)}[ï¼Œ,:ï¼š\s]*{re.escape(KEYWORD_TASK)}[ï¼Œ,:ï¼š\s]*"
)
NORMALIZE_SPACE_RE = re.compile(r"[ \t]+")
NORMALIZE_REMOVE_RE = re.compile(r"[åˆ†äº«\sã€‚ï¼Â·!ï¼?ï¼Ÿã€,.ï¼Œ:ï¼š;ï¼›\-]+")

# ========== ä¸Šä¸‹æ–‡çŠ¶æ€ç®¡ç† ==========
class PendingCommand:
    """ç­‰å¾…å†…å®¹çš„å‘½ä»¤çŠ¶æ€"""
    def __init__(self, command_type: str, timestamp: float):
        self.command_type = command_type  # "è®°ç¬”è®°" æˆ– "è®°ä»»åŠ¡"
        self.timestamp = timestamp

    def is_expired(self, timeout_seconds: float = 30.0) -> bool:
        """æ£€æŸ¥å‘½ä»¤æ˜¯å¦å·²è¿‡æœŸï¼ˆé»˜è®¤30ç§’è¶…æ—¶ï¼‰"""
        import time
        return time.time() - self.timestamp > timeout_seconds

# å…¨å±€çŠ¶æ€ï¼šç­‰å¾…å†…å®¹çš„å‘½ä»¤
pending_command: PendingCommand | None = None

# ========== ç»Ÿè®¡è®¡æ•°å™¨ ==========
class DailyStats:
    """ä»Šæ—¥ç»Ÿè®¡æ•°æ®"""
    def __init__(self):
        self.notes_count = 0
        self.tasks_count = 0
        self.last_record_time = None
        self.date = datetime.now().strftime("%Y-%m-%d")
        # æ€§èƒ½ç›‘æ§
        self.processed_messages = 0
        self.duplicate_skipped = 0
        self.start_time = time.time()

    def reset_if_new_day(self):
        """å¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®è®¡æ•°å™¨"""
        current_date = datetime.now().strftime("%Y-%m-%d")
        if current_date != self.date:
            self.notes_count = 0
            self.tasks_count = 0
            self.last_record_time = None
            self.date = current_date
            self.processed_messages = 0
            self.duplicate_skipped = 0
            self.start_time = time.time()

    def add_note(self):
        """æ·»åŠ ç¬”è®°è®¡æ•°"""
        self.reset_if_new_day()
        self.notes_count += 1
        self.last_record_time = datetime.now()

    def add_task(self):
        """æ·»åŠ ä»»åŠ¡è®¡æ•°"""
        self.reset_if_new_day()
        self.tasks_count += 1
        self.last_record_time = datetime.now()

    def add_processed_message(self):
        """å¢åŠ å¤„ç†æ¶ˆæ¯è®¡æ•°"""
        self.processed_messages += 1

    def add_duplicate_skipped(self):
        """å¢åŠ è·³è¿‡é‡å¤æ¶ˆæ¯è®¡æ•°"""
        self.duplicate_skipped += 1

    def get_summary(self) -> str:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        self.reset_if_new_day()
        total = self.notes_count + self.tasks_count
        uptime = time.time() - self.start_time
        uptime_str = f"{int(uptime//3600)}h{int((uptime%3600)//60)}m"
        return f"ä»Šæ—¥è®°å½•: {total} æ¡ (ç¬”è®°{self.notes_count}, ä»»åŠ¡{self.tasks_count})\nè¿è¡Œæ—¶é—´: {uptime_str}, å¤„ç†: {self.processed_messages}, è·³è¿‡: {self.duplicate_skipped}"

# å…¨å±€ç»Ÿè®¡å®ä¾‹
daily_stats = DailyStats()

# ========== æ—¶é—´å·¥å…· ==========
def today() -> str:
    """è·å–ä»Šå¤©çš„æ—¥æœŸå­—ç¬¦ä¸²"""
    return datetime.now().strftime("%Y-%m-%d")


def hhmm(timestamp: int | None = None) -> str:
    """è·å–æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ”¯æŒUnixæ—¶é—´æˆ³æˆ–å½“å‰æ—¶é—´"""
    if timestamp:
        return datetime.fromtimestamp(timestamp).strftime("%H:%M:%S")
    return datetime.now().strftime("%H:%M:%S")


# ========== æ–‡æœ¬å½’ä¸€åŒ– & å»é‡ ==========
# å†…å­˜ç¼“å­˜ï¼šæœ€è¿‘å¤„ç†è¿‡çš„å†…å®¹å“ˆå¸Œ
_recent_hashes = set()
_max_cache_size = 1000

def normalize_text(text: str) -> str:
    """æ¸…æ´—æ–‡æœ¬ï¼šå»"åˆ†äº«"ã€åˆå¹¶é‡å¤å‰ç¼€ã€ç»Ÿä¸€åˆ†éš”ç¬¦ã€å‹ç¼©ç©ºç™½"""
    result = (text or "").replace("\u200b", "").replace("åˆ†äº«", "")

    result = NORMALIZE_NOTE_RE.sub(f"{KEYWORD_NOTE} ", result)
    result = NORMALIZE_TASK_RE.sub(f"{KEYWORD_TASK} ", result)
    result = NORMALIZE_SPACE_RE.sub(" ", result)

    # æ¸…ç†æœ«å°¾çš„æ ‡ç‚¹ç¬¦å·ï¼ˆå¥å·ã€é€—å·ã€æ„Ÿå¹å·ã€é—®å·ç­‰ï¼‰
    result = result.strip()
    while result and result[-1] in "ã€‚ï¼Œï¼ï¼Ÿã€ï¼›ï¼š":
        result = result[:-1].strip()

    return result


def compute_dedup_hash(text: str) -> str:
    """å¯¹å»å™ªå†…å®¹åšå“ˆå¸Œï¼Œç”¨äºå»é‡"""
    base = normalize_text(text)
    base = NORMALIZE_REMOVE_RE.sub("", base)
    return hashlib.sha256(base.encode()).hexdigest()


def is_recently_processed(text: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦æœ€è¿‘å·²å¤„ç†è¿‡ï¼ˆå†…å­˜ç¼“å­˜ï¼‰ï¼Œä¼˜åŒ–å»é‡ç­–ç•¥"""
    global _recent_hashes

    # å¯¹äºå…³é”®è¯æ¶ˆæ¯ï¼Œä½¿ç”¨æ›´å®½æ¾çš„å»é‡ç­–ç•¥
    if KEYWORD_NOTE in text or KEYWORD_TASK in text:
        # åªå¯¹å®Œå…¨ç›¸åŒçš„å†…å®¹è¿›è¡Œå»é‡ï¼Œé¿å…è¯¯åˆ¤
        text_hash = hashlib.sha256(text.encode()).hexdigest()
    else:
        # å¯¹äºéå…³é”®è¯æ¶ˆæ¯ï¼Œä½¿ç”¨åŸæœ‰çš„å½’ä¸€åŒ–å»é‡
        text_hash = compute_dedup_hash(text)

    if text_hash in _recent_hashes:
        return True

    # æ·»åŠ åˆ°ç¼“å­˜
    _recent_hashes.add(text_hash)

    # é™åˆ¶ç¼“å­˜å¤§å°
    if len(_recent_hashes) > _max_cache_size:
        # æ¸…ç†ä¸€åŠç¼“å­˜
        _recent_hashes = set(list(_recent_hashes)[_max_cache_size//2:])

    return False

# ========== SQLite æ•°æ®åº“ ==========
DB: sqlite3.Connection | None = None
DB_LOCK = threading.Lock()


def init_database() -> None:
    """åˆå§‹åŒ–å…¨å±€æ•°æ®åº“è¿æ¥ï¼Œä½¿ç”¨ WAL æ¨¡å¼"""
    global DB
    DB_PATH.parent.mkdir(parents=True, exist_ok=True)
    DB = sqlite3.connect(DB_PATH, check_same_thread=False)
    DB.execute("PRAGMA journal_mode=WAL;")
    DB.execute("PRAGMA synchronous=NORMAL;")
    DB.execute("CREATE TABLE IF NOT EXISTS seen(id TEXT PRIMARY KEY, ts REAL)")
    DB.commit()
    atexit.register(lambda: DB and DB.close())


def cleanup_old_records(horizon_hours: int = 36) -> None:
    """æ¸…ç†è¶…è¿‡ horizon_hours çš„æ—§è®°å½•"""
    cutoff = time.time() - max(1, horizon_hours) * 3600
    with DB_LOCK:
        cursor = DB.execute("DELETE FROM seen WHERE ts < ?", (cutoff,))
        deleted = cursor.rowcount
        DB.commit()
        if DEBUG and deleted > 0:
            logger.debug(f"æ¸…ç†äº† {deleted} æ¡è¿‡æœŸè®°å½•")


def is_duplicate_or_mark_seen(key: str, horizon_hours: int = 36) -> bool:
    """
    æ»‘åŠ¨çª—å£å»é‡ï¼šè‹¥ key åœ¨æœ€è¿‘ horizon_hours å°æ—¶å†…è§è¿‡åˆ™è¿”å› Trueï¼ˆé‡å¤ï¼‰ï¼Œ
    å¦åˆ™æ’å…¥/æ›´æ–°æ—¶é—´æˆ³å¹¶è¿”å› Falseï¼ˆé¦–æ¬¡/è¿‡æœŸï¼‰
    """
    now = time.time()
    cutoff = now - max(1, horizon_hours) * 3600

    with DB_LOCK:
        row = DB.execute("SELECT ts FROM seen WHERE id=?", (key,)).fetchone()
        if row:
            last_ts = row[0] or 0.0
            DB.execute("UPDATE seen SET ts=? WHERE id=?", (now, key))
            DB.commit()
            return last_ts >= cutoff

        DB.execute("INSERT INTO seen(id, ts) VALUES(?, ?)", (key, now))
        DB.commit()
        return False

# ========== å¹¶å‘æ§åˆ¶ ==========
WRITE_SEMAPHORE = asyncio.Semaphore(5)


# ========== ç³»ç»Ÿé€šçŸ¥ ==========
def send_notification(title: str, message: str) -> None:
    """å‘é€ç³»ç»Ÿé€šçŸ¥"""
    try:
        notification.notify(
            title=title,
            message=message,
            app_name="è±†åŒ…è¯­éŸ³ç¬”è®°",
            timeout=3
        )
    except Exception as e:
        logger.debug(f"å‘é€é€šçŸ¥å¤±è´¥: {e}")


# ========== æ–‡ä»¶å†™å…¥ ==========
async def append_to_file(path: Path, text: str) -> None:
    """è¿½åŠ æ–‡æœ¬åˆ°æ–‡ä»¶ï¼Œè‡ªåŠ¨åˆ›å»ºçˆ¶ç›®å½•"""
    path.parent.mkdir(parents=True, exist_ok=True)
    async with aiofiles.open(path, "a", encoding="utf-8") as f:
        await f.write(text)


async def write_to_obsidian(content: str, kind: str, timestamp: int | None = None) -> None:
    """ç»Ÿä¸€å†™å…¥æ¥å£"""
    async with WRITE_SEMAPHORE:
        try:
            if kind == KEYWORD_NOTE:
                filepath = VAULT / NOTES_DIR / f"{today()}.md"
                prefix = f"- [{hhmm(timestamp)}] "
                logger.info(f"ç›®æ ‡æ–‡ä»¶: {filepath}")
                # æ›´æ–°ç»Ÿè®¡
                daily_stats.add_note()
                # å‘é€é€šçŸ¥
                send_notification("ğŸ“ ç¬”è®°å·²è®°å½•", f"{content.strip()}")
            else:
                filepath = VAULT / TASKS_DIR / f"{today()}.md"
                prefix = "- [ ] "
                logger.info(f"ç›®æ ‡æ–‡ä»¶: {filepath}")
                # æ›´æ–°ç»Ÿè®¡
                daily_stats.add_task()
                # å‘é€é€šçŸ¥
                send_notification("âœ… ä»»åŠ¡å·²æ·»åŠ ", f"{content.strip()}")

            await append_to_file(filepath, f"{prefix}{content.strip()}\n")
            logger.info(f"å†™å…¥{kind}: {content.strip()}")
        except IOError as e:
            logger.error(f"å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")
            raise

# ========== æ–‡æœ¬æå– ==========
JSON_TEXT_KEYS = ("text", "content", "message", "delta", "display_text")


def extract_texts_from_json(obj: Any) -> list[tuple[str, int | None]]:
    """ä» JSON å¯¹è±¡ä¸­é€’å½’æå–åŒ…å«å…³é”®è¯çš„æ–‡æœ¬ï¼Œè¿”å› (æ–‡æœ¬, æ—¶é—´æˆ³) å…ƒç»„åˆ—è¡¨"""
    results = []

    def pick(item: Any, timestamp: int | None = None, is_user_message: bool = True) -> None:
        if isinstance(item, str):
            # åªæœ‰åœ¨æ˜¯ç”¨æˆ·æ¶ˆæ¯æ—¶æ‰æå–æ–‡æœ¬
            if is_user_message and (KEYWORD_NOTE in item or KEYWORD_TASK in item):
                results.append((item, timestamp))
        elif isinstance(item, list):
            for element in item:
                pick(element, timestamp, is_user_message)
        elif isinstance(item, dict):
            # æ£€æŸ¥æ˜¯å¦æ˜¯è±†åŒ…çš„æ¶ˆæ¯ï¼ˆè¿‡æ»¤æ‰è±†åŒ…çš„å›å¤ï¼‰
            current_is_user_message = is_user_message
            if "user_type" in item:
                # user_type = 2 è¡¨ç¤ºè±†åŒ…çš„æ¶ˆæ¯ï¼Œéœ€è¦è¿‡æ»¤æ‰
                current_is_user_message = item["user_type"] != 2
            elif "sender_id" in item:
                # ç‰¹å®šçš„ sender_id ä¹Ÿå¯èƒ½è¡¨ç¤ºè±†åŒ…
                # ä»æ—¥å¿—ä¸­çœ‹åˆ°è±†åŒ…çš„ sender_id æ˜¯ "7234781073513644036"
                current_is_user_message = item["sender_id"] != "7234781073513644036"

            # å°è¯•æå–æ—¶é—´æˆ³
            current_timestamp = None
            if "create_time" in item:
                try:
                    current_timestamp = int(item["create_time"])
                except (ValueError, TypeError):
                    pass

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¶é—´æˆ³ï¼Œä½¿ç”¨çˆ¶çº§ä¼ é€’çš„æ—¶é—´æˆ³
            if current_timestamp is None:
                current_timestamp = timestamp

            for key in JSON_TEXT_KEYS:
                if key in item:
                    pick(item[key], current_timestamp, current_is_user_message)
            for value in item.values():
                pick(value, current_timestamp, current_is_user_message)

    pick(obj)
    return results[:50]


def extract_texts(raw: str) -> list[tuple[str, int | None]]:
    """ä»å­—ç¬¦ä¸²æˆ– JSON ä¸­æå–æ–‡æœ¬åˆ—è¡¨ï¼Œè¿”å› (æ–‡æœ¬, æ—¶é—´æˆ³) å…ƒç»„åˆ—è¡¨"""
    text = (raw or "").strip()
    if not text:
        return []

    try:
        if (text.startswith("{") and text.endswith("}")) or (text.startswith("[") and text.endswith("]")):
            try:
                obj = json.loads(text)
                results = extract_texts_from_json(obj)
                if results:
                    return results
            except json.JSONDecodeError:
                pass

        matches = re.findall(r'"(?:text|content|message|delta|display_text)"\s*:\s*"(.*?)"', text)
        if matches:
            return [(re.sub(r'\\(["\\/bfnrt])', r'\1', m), None) for m in matches]
    except Exception as e:
        logger.warning(f"æå–æ–‡æœ¬æ—¶å‡ºé”™: {e}")

    return [(text, None)]


def is_keyword_only_message(text: str) -> str | None:
    """æ£€æµ‹æ˜¯å¦ä¸ºåªåŒ…å«å…³é”®è¯çš„æ¶ˆæ¯ï¼Œè¿”å›å…³é”®è¯ç±»å‹æˆ–None"""
    normalized = normalize_text(text)
    if not normalized:
        return None

    # ä½¿ç”¨ä¸CMD_REç›¸åŒçš„å…³é”®è¯å˜ä½“ï¼Œä½†åªåŒ¹é…å…³é”®è¯éƒ¨åˆ†ï¼ˆæ²¡æœ‰å†…å®¹ï¼‰
    # æ„å»ºæ‰€æœ‰å¯èƒ½çš„å…³é”®è¯å˜ä½“
    note_variants = [
        KEYWORD_NOTE, "ç¬”è®°", "å‡ ç¬”è®°", "åŠç¬”è®°", "å³ç¬”è®°", "å¯„ç¬”è®°",
        "è®°ä¸ªç¬”è®°", "è®°ä¸€ä¸‹ç¬”è®°", "è®°å½•ç¬”è®°", "è®°1ä¸ªç¬”è®°", "è®°ä¸€ä¸ªç¬”è®°",
        "å¸®æˆ‘è®°ç¬”è®°", "å¸®æˆ‘è®°ä¸ªç¬”è®°", "å¸®æˆ‘è®°ä¸€ä¸‹ç¬”è®°",
        "è®°è®°ç¬”è®°", "ç¬”ç¬”è®°", "è®°æ¯”è®°"
    ]
    task_variants = [
        KEYWORD_TASK, "ä»»åŠ¡", "å‡ ä»»åŠ¡", "åŠä»»åŠ¡", "å³ä»»åŠ¡", "å¯„ä»»åŠ¡",
        "è®°ä¸ªä»»åŠ¡", "è®°ä¸€ä¸‹ä»»åŠ¡", "è®°å½•ä»»åŠ¡", "è®°1ä¸ªä»»åŠ¡", "è®°ä¸€ä¸ªä»»åŠ¡",
        "æ·»åŠ ä»»åŠ¡", "æ–°å¢ä»»åŠ¡", "åˆ›å»ºä»»åŠ¡",
        "å¸®æˆ‘è®°ä»»åŠ¡", "å¸®æˆ‘è®°ä¸ªä»»åŠ¡", "å¸®æˆ‘æ·»åŠ ä»»åŠ¡", "å¸®æˆ‘è®°ä¸€ä¸‹ä»»åŠ¡",
        "è®°è®°ä»»åŠ¡", "ä»»ä»»åŠ¡", "äººåŠ¡", "è®¤åŠ¡", "ä»åŠ¡"
    ]

    all_variants = note_variants + task_variants
    variants_pattern = "|".join(re.escape(v) for v in all_variants)

    # åŒ…å«è¯­æ°”è¯å’Œå¡«å……è¯çš„åŒ¹é…
    filler_words = r"(?:å—¯[ï¼Œ,\s]*|é‚£ä¸ª[ï¼Œ,\s]*|OK[ï¼Œ,\s]*|å¥½çš„[ï¼Œ,\s]*|å‘ƒ[ï¼Œ,\s]*)?"

    # æ£€æŸ¥æ˜¯å¦åªåŒ…å«å…³é”®è¯ï¼ˆå¯èƒ½å¸¦è±†åŒ…è±†åŒ…å‰ç¼€å’Œè¯­æ°”è¯ï¼‰
    keyword_only_pattern = rf"^\s*{filler_words}(?:è±†åŒ…è±†åŒ…[ï¼Œ,:ï¼šã€‚\s]*)?{filler_words}(?:å¸®æˆ‘\s*)?({variants_pattern})(?:[ï¼Œ,:ï¼šã€‚\så§å‘¢å•Š]*)?$"
    match = re.match(keyword_only_pattern, normalized, re.IGNORECASE)
    if match:
        return normalize_matched_keyword(match.group(1))
    return None


def is_content_message(text: str) -> bool:
    """æ£€æµ‹æ˜¯å¦ä¸ºçº¯å†…å®¹æ¶ˆæ¯ï¼ˆä¸åŒ…å«å…³é”®è¯ï¼‰"""
    normalized = normalize_text(text)
    if not normalized:
        return False

    # æ£€æŸ¥æ˜¯å¦ä¸åŒ…å«å…³é”®è¯ï¼Œä½†æœ‰å®é™…å†…å®¹
    has_keyword = KEYWORD_NOTE in normalized or KEYWORD_TASK in normalized
    has_content = len(normalized.strip()) > 0

    return has_content and not has_keyword


# ========== æ¶ˆæ¯å¤„ç† ==========
async def handle_text(source: str, raw_text: str) -> None:
    """å¤„ç†æ–‡æœ¬ï¼ŒåŒ¹é…å‘½ä»¤å¹¶å†™å…¥ç¬”è®°æˆ–ä»»åŠ¡ï¼Œæ”¯æŒåˆ†ç¦»çš„å…³é”®è¯å’Œå†…å®¹"""
    global pending_command
    import time

    try:
        candidates = extract_texts(raw_text)
        prefix_pattern = rf"^(?:è±†åŒ…è±†åŒ…[ï¼Œ,:ï¼šã€‚\s]*)?(?:{re.escape(KEYWORD_NOTE)}|{re.escape(KEYWORD_TASK)})[ï¼š:ï¼Œ,ã€‚\s]+"

        for raw, msg_timestamp in candidates:
            normalized = normalize_text(raw)
            if not normalized:
                continue

            for line in normalized.splitlines():
                line = line.strip()
                if not line:
                    continue

                # å¿«é€Ÿå†…å­˜ç¼“å­˜æ£€æŸ¥ï¼Œé¿å…é‡å¤å¤„ç†
                if is_recently_processed(line):
                    daily_stats.add_duplicate_skipped()
                    if should_log_debug(f"{source}_duplicate", 60):
                        logger.debug(f"[{source}] æœ€è¿‘å·²å¤„ç†è¿‡çš„å†…å®¹ï¼Œè·³è¿‡")
                    continue

                # è®°å½•å¤„ç†çš„æ¶ˆæ¯
                daily_stats.add_processed_message()

                # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…ä¸­çš„å‘½ä»¤å·²è¿‡æœŸï¼Œå¦‚æœè¿‡æœŸåˆ™æ¸…é™¤
                if pending_command and pending_command.is_expired():
                    if should_log_debug(f"{source}_expired", 30):
                        logger.debug(f"[{source}] ç­‰å¾…ä¸­çš„å‘½ä»¤å·²è¿‡æœŸï¼Œæ¸…é™¤: {pending_command.command_type}")
                    pending_command = None

                # æƒ…å†µ1: æ£€æŸ¥æ˜¯å¦ä¸ºåªåŒ…å«å…³é”®è¯çš„æ¶ˆæ¯
                keyword_type = is_keyword_only_message(line)
                if keyword_type:
                    pending_command = PendingCommand(keyword_type, time.time())
                    if should_log_debug(f"{source}_keyword", 10):
                        logger.debug(f"[{source}] æ£€æµ‹åˆ°å…³é”®è¯ï¼Œç­‰å¾…å†…å®¹: {keyword_type}")
                    continue

                # æƒ…å†µ2: æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…ä¸­çš„å‘½ä»¤ï¼Œä¸”å½“å‰æ¶ˆæ¯ä¸ºçº¯å†…å®¹
                if pending_command and is_content_message(line):
                    kind = pending_command.command_type
                    content = line.strip()

                    # æ¸…é™¤ç­‰å¾…çŠ¶æ€
                    pending_command = None

                    if should_log_debug(f"{source}_context", 5):
                        logger.debug(f"[{source}] å…³è”ä¸Šä¸‹æ–‡: {kind} -> {content}")

                    # å»é‡æ£€æŸ¥
                    dedup_key = compute_dedup_hash(kind + "|" + content)
                    if is_duplicate_or_mark_seen(dedup_key, horizon_hours=DEDUP_HOURS):
                        if should_log_debug(f"{source}_duplicate_db", 60):
                            logger.debug(f"[{source}] æ•°æ®åº“é‡å¤å†…å®¹ï¼Œè·³è¿‡: {content}")
                        continue

                    await write_to_obsidian(content, kind, msg_timestamp)
                    if should_log_debug(f"{source}_write", 5):
                        logger.debug(f"[{source}] ä¸Šä¸‹æ–‡å…³è”å¹¶å†™å…¥")
                    continue

                # æƒ…å†µ3: ä¼ ç»Ÿçš„å•æ¡æ¶ˆæ¯åŒ…å«å…³é”®è¯å’Œå†…å®¹
                match = CMD_RE.match(line)
                if not match:
                    continue

                kind, content = normalize_matched_keyword(match.group(1)), match.group(2).strip()
                content = re.sub(prefix_pattern, "", content).strip()

                # å»é‡æ£€æŸ¥
                dedup_key = compute_dedup_hash(kind + "|" + content)
                if is_duplicate_or_mark_seen(dedup_key, horizon_hours=DEDUP_HOURS):
                    if should_log_debug(f"{source}_duplicate_db", 60):
                        logger.debug(f"[{source}] æ•°æ®åº“é‡å¤å†…å®¹ï¼Œè·³è¿‡: {content}")
                    continue

                await write_to_obsidian(content, kind, msg_timestamp)
                if should_log_debug(f"{source}_write", 5):
                    logger.debug(f"[{source}] ä¼ ç»Ÿæ¨¡å¼å‘½ä¸­å¹¶å†™å…¥")

    except Exception as e:
        logger.error(f"å¤„ç†æ–‡æœ¬æ—¶å‡ºé”™ [{source}]: {e}")

# ========== é¡µé¢æŠ“å–é€šé“ ==========
async def poll_dom(page: Page) -> None:
    """DOM è½®è¯¢ï¼šæ‰«ææœ€è¿‘æ¶ˆæ¯ï¼Œå¢å¼ºæ£€æµ‹èƒ½åŠ›"""
    try:
        # å¤šç§é€‰æ‹©å™¨ç­–ç•¥ï¼Œæé«˜æ•è·ç‡
        selectors = [
            # åŸæœ‰é€‰æ‹©å™¨
            f":is(div,li,article,section,p,span):has-text('{KEYWORD_NOTE}')",
            f":is(div,li,article,section,p,span):has-text('{KEYWORD_TASK}')",
            # æ–°å¢æ›´å¹¿æ³›çš„é€‰æ‹©å™¨
            f"[class*='message']:has-text('{KEYWORD_NOTE}')",
            f"[class*='message']:has-text('{KEYWORD_TASK}')",
            f"[class*='chat']:has-text('{KEYWORD_NOTE}')",
            f"[class*='chat']:has-text('{KEYWORD_TASK}')",
            f"[class*='content']:has-text('{KEYWORD_NOTE}')",
            f"[class*='content']:has-text('{KEYWORD_TASK}')",
        ]

        all_texts = set()  # ç”¨äºå»é‡

        for selector in selectors:
            try:
                nodes = page.locator(selector)
                count = await nodes.count()
                # å¢åŠ æ‰«æèŒƒå›´ï¼šä»æœ€è¿‘10æ¡å¢åŠ åˆ°20æ¡
                start = max(0, count - 20)

                for i in range(start, count):
                    try:
                        raw = await nodes.nth(i).inner_text()
                        if raw and raw not in all_texts:
                            all_texts.add(raw)
                            await handle_text("DOM", raw)
                    except Exception as e:
                        if should_log_debug("dom_extract_error", 60):
                            logger.debug(f"DOM å…ƒç´ æå–å¼‚å¸¸: {e}")
            except Exception as e:
                if should_log_debug("dom_selector_error", 60):
                    logger.debug(f"DOM é€‰æ‹©å™¨å¼‚å¸¸ [{selector}]: {e}")

    except Exception as e:
        logger.error(f"DOM è½®è¯¢å¼‚å¸¸: {e}")


def build_mutation_observer_js() -> str:
    """æ„å»ºçœŸæ­£å®æ—¶çš„ MutationObserver JavaScript ä»£ç """
    kw_note = KEYWORD_NOTE.replace('\\', '\\\\').replace('/', '\\/')
    kw_task = KEYWORD_TASK.replace('\\', '\\\\').replace('/', '\\/')
    return f"""
(() => {{
  console.log('ğŸš€ è±†åŒ…å®æ—¶ç›‘æ§å·²å¯åŠ¨');

  const send = window.__emitMessage || (()=>{{}});
  const processed = new Set();
  let messageQueue = [];
  let isProcessing = false;

  // å®æ—¶å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—
  const processQueue = async () => {{
    if (isProcessing || messageQueue.length === 0) return;
    isProcessing = true;

    while (messageQueue.length > 0) {{
      const text = messageQueue.shift();
      const hash = btoa(unescape(encodeURIComponent(text))).slice(0,20);

      if (!processed.has(hash)) {{
        processed.add(hash);
        console.log('ğŸ“ å‘ç°å…³é”®è¯æ¶ˆæ¯:', text.slice(0, 100));
        send(text);
      }}
    }}

    isProcessing = false;
  }};

  const scanElement = (element) => {{
    if (!element || element.nodeType !== 1) return;

    const text = (element.innerText || element.textContent || '').trim();
    if (text && text.length > 0 && text.length < 4000) {{
      if (/{kw_note}|{kw_task}/.test(text)) {{
        messageQueue.push(text);
        processQueue();
      }}
    }}
  }};

  // é«˜é¢‘å®æ—¶ç›‘æ§
  const observer = new MutationObserver((mutations) => {{
    mutations.forEach((mutation) => {{
      // ç›‘æ§æ–°å¢èŠ‚ç‚¹
      if (mutation.addedNodes) {{
        mutation.addedNodes.forEach((node) => {{
          if (node.nodeType === 1) {{
            scanElement(node);
            // é€’å½’æ‰«ææ‰€æœ‰å­èŠ‚ç‚¹
            if (node.querySelectorAll) {{
              node.querySelectorAll('*').forEach(scanElement);
            }}
          }}
        }});
      }}

      // ç›‘æ§æ–‡æœ¬å†…å®¹å˜åŒ–
      if (mutation.type === 'characterData') {{
        const parent = mutation.target.parentElement;
        if (parent) scanElement(parent);
      }}

      // ç›‘æ§å±æ€§å˜åŒ–ï¼ˆå¯èƒ½å½±å“æ˜¾ç¤ºçš„æ–‡æœ¬ï¼‰
      if (mutation.type === 'attributes' && mutation.target) {{
        scanElement(mutation.target);
      }}
    }});
  }});

  // å¯åŠ¨å…¨é¢ç›‘æ§
  observer.observe(document.documentElement, {{
    childList: true,
    subtree: true,
    characterData: true,
    attributes: true,
    attributeFilter: ['class', 'style', 'data-*']
  }});

  // åˆå§‹å…¨é¡µé¢æ‰«æ
  document.querySelectorAll('*').forEach(scanElement);

  // å®šæœŸæ¸…ç†ç¼“å­˜
  setInterval(() => {{
    if (processed.size > 2000) {{
      const arr = Array.from(processed);
      processed.clear();
      arr.slice(-1000).forEach(h => processed.add(h));
      console.log('ğŸ§¹ æ¸…ç†ç›‘æ§ç¼“å­˜');
    }}
  }}, 30000);

  // ç›‘æ§é¡µé¢ç„¦ç‚¹å˜åŒ–ï¼Œç¡®ä¿ä¸é—æ¼
  document.addEventListener('visibilitychange', () => {{
    if (!document.hidden) {{
      setTimeout(() => {{
        document.querySelectorAll('*').forEach(scanElement);
      }}, 1000);
    }}
  }});

  // ç›‘æ§æ»šåŠ¨äº‹ä»¶ï¼Œæ‰«ææ–°å‡ºç°çš„å†…å®¹
  let scrollTimeout;
  document.addEventListener('scroll', () => {{
    clearTimeout(scrollTimeout);
    scrollTimeout = setTimeout(() => {{
      const viewportElements = document.elementsFromPoint(
        window.innerWidth / 2,
        window.innerHeight / 2
      );
      viewportElements.forEach(scanElement);
    }}, 500);
  }}, {{ passive: true }});

  console.log('âœ… è±†åŒ…å®æ—¶ç›‘æ§é…ç½®å®Œæˆ');
}})();
"""


MUTATION_JS = build_mutation_observer_js()


async def brute_scrape(page: Page) -> None:
    """æš´åŠ›æ‰«æï¼šéå†æ‰€æœ‰ frame çš„ innerText"""
    try:
        for frame in page.frames:
            try:
                txt = await frame.evaluate(
                    "document.body ? document.body.innerText.slice(0,50000) : ''"
                )
                if txt:
                    await handle_text("Brute", txt)
            except Exception as e:
                if DEBUG:
                    logger.debug(f"Brute å­å¸§å¼‚å¸¸ [{getattr(frame, 'url', 'unknown')}]: {e}")
    except Exception as e:
        logger.error(f"Brute æ‰«æå¼‚å¸¸: {e}")

# ========== æµè§ˆå™¨å¯åŠ¨ ==========
BROWSER_CANDIDATES = [
    "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome",
    "/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge",
]


def find_local_chromium(browsers_dir: str) -> str | None:
    """æŸ¥æ‰¾æœ¬åœ° Chromium å¯æ‰§è¡Œæ–‡ä»¶"""
    if not os.path.isdir(browsers_dir):
        return None

    for name in sorted(os.listdir(browsers_dir), reverse=True):
        if name.startswith("chromium-"):
            exe = os.path.join(
                browsers_dir, name, "chrome-mac", "Chromium.app",
                "Contents", "MacOS", "Chromium"
            )
            if os.path.exists(exe):
                return exe
    return None


async def start_browser(
    playwright: Any,
    force_headless: bool = False
) -> tuple[Browser, str, bool]:
    """å¯åŠ¨æµè§ˆå™¨ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ° Chromium

    Args:
        playwright: Playwright å®ä¾‹
        force_headless: å¼ºåˆ¶ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼ˆç”¨äºå·²ç™»å½•åçš„ç›‘å¬ï¼‰

    Returns:
        tuple: (browser, executable_path, headless)
    """
    script_dir = Path(__file__).parent.resolve()
    default_browsers = str(script_dir / "pw-browsers")
    browsers_path = os.getenv("PLAYWRIGHT_BROWSERS_PATH", default_browsers)

    local_chromium = find_local_chromium(browsers_path)
    candidates = [local_chromium] + BROWSER_CANDIDATES + [None]

    headless = force_headless or (not HEADFUL and STATE_PATH.exists())
    last_error = None

    for exe in candidates:
        try:
            launch_args: dict[str, Any] = {
                "headless": headless,
                "args": ["--no-first-run", "--no-default-browser-check"]
            }
            if exe and os.path.exists(exe):
                launch_args["executable_path"] = exe
                if headless:
                    launch_args["args"].append("--headless=new")

            logger.info(f"å‡†å¤‡å¯åŠ¨æµè§ˆå™¨ï¼šexe={exe or 'playwright-default'}, headless={headless}")
            browser = await playwright.chromium.launch(**launch_args)
            return browser, exe or "playwright-default", headless
        except Exception as e:
            last_error = e
            logger.warning(f"å¯åŠ¨å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªï¼š{e}")

    raise RuntimeError(f"æ‰€æœ‰å€™é€‰æµè§ˆå™¨å‡å¤±è´¥ï¼š{last_error}")

# ========== Observer æ³¨å…¥ ==========
async def inject_observer_to_page(page: Page) -> None:
    """å‘é¡µé¢æ³¨å…¥å®æ—¶ç›‘æ§ MutationObserver"""
    try:
        await page.expose_function(
            "__emitMessage",
            lambda s: asyncio.create_task(handle_text("Observer", s))
        )
    except Exception:
        pass  # å·²æš´éœ²è¿‡åˆ™å¿½ç•¥

    # æ³¨å…¥æ´»è·ƒçŠ¶æ€æ ‡è®°
    await page.evaluate("window.__observerActive = true;")

    for frame in page.frames:
        try:
            await frame.evaluate(MUTATION_JS)
            await frame.evaluate("window.__observerActive = true;")
        except Exception as e:
            if should_log_debug("inject_frame_error", 60):
                logger.debug(f"[Frame {getattr(frame, 'url', 'unknown')}] evaluate å¤±è´¥: {e}")

    logger.info("ğŸš€ å®æ—¶ç›‘æ§å·²æ³¨å…¥é¡µé¢")


async def inject_to_frame(frame: Any) -> None:
    """å‘å•ä¸ª frame æ³¨å…¥ Observer"""
    try:
        await frame.evaluate(MUTATION_JS)
    except Exception:
        pass

# ========== ä¸»é€»è¾‘ ==========
USER_AGENT = (
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
)
NETWORK_URL_KEYWORDS = (
    # åŸæœ‰å…³é”®è¯
    "samantha", "alice", "message", "chat", "conversation", "stream", "history",
    # æ–°å¢è±†åŒ…ç›¸å…³å…³é”®è¯
    "doubao", "im", "chain", "single", "pull", "push", "sync", "api",
    # é€šç”¨èŠå¤©å…³é”®è¯
    "send", "receive", "reply", "response", "content", "text"
)


def has_valid_login_cookies(cookies: list[dict]) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„è±†åŒ…ç™»å½• cookie
    è±†åŒ…ç™»å½•åä¼šè®¾ç½®ç‰¹å®šçš„è®¤è¯ cookieï¼Œå¦‚ sessionidã€passport_csrf_token ç­‰
    """
    if not cookies:
        return False

    doubao_cookies = [c for c in cookies if 'doubao.com' in c.get('domain', '')]

    if len(doubao_cookies) < 5:
        return False

    auth_cookie_names = {
        'sessionid', 'sessionid_ss', 'passport_csrf_token',
        'sid_guard', 'sid_tt', 'uid_tt', 'ssid_ucp_v1',
        'ttwid', 'passport_auth_status'
    }

    cookie_names = {c.get('name', '') for c in doubao_cookies}
    matched = auth_cookie_names & cookie_names

    return len(matched) >= 3


async def wait_for_login(context: BrowserContext, browser: Browser) -> bool:
    """
    ç­‰å¾…ç”¨æˆ·ç™»å½•ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ

    æ ¸å¿ƒé€»è¾‘ï¼šæŒç»­ç›‘æµ‹ cookieï¼Œåªæœ‰æ£€æµ‹åˆ°æœ‰æ•ˆçš„ç™»å½• cookie æ‰ç®—æˆåŠŸ
    å®¹é”™ç”¨æˆ·çš„å„ç§æ“ä½œï¼ˆåˆ·æ–°ã€è·³è½¬ç­‰ï¼‰ï¼Œåªè¦æœ€ç»ˆç™»å½•æˆåŠŸå³å¯
    """
    logger.info("é¦–æ¬¡è¿è¡Œï¼šè¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨ä¸­ç™»å½•è±†åŒ…...")
    logger.info("ç™»å½•æˆåŠŸåå°†è‡ªåŠ¨ä¿å­˜ Cookie å¹¶å…³é—­æµè§ˆå™¨")
    logger.info("ï¼ˆæ‚¨å¯ä»¥æ­£å¸¸æ“ä½œæµè§ˆå™¨ï¼Œåˆ·æ–°é¡µé¢ä¸ä¼šå½±å“ç™»å½•æ£€æµ‹ï¼‰")

    stable_count = 0
    max_wait_seconds = 300
    check_interval = 2

    for i in range(max_wait_seconds // check_interval):
        await asyncio.sleep(check_interval)

        try:
            cookies = await context.cookies()

            if has_valid_login_cookies(cookies):
                stable_count += 1
                if DEBUG:
                    logger.debug(f"æ£€æµ‹åˆ°æœ‰æ•ˆç™»å½• cookieï¼Œç¨³å®šè®¡æ•°: {stable_count}/3")

                if stable_count >= 3:
                    await context.storage_state(path=str(STATE_PATH))

                    logger.info("========================================")
                    logger.info("  ç™»å½•æˆåŠŸï¼Cookie å·²ä¿å­˜")
                    logger.info("  æµè§ˆå™¨å°†åœ¨ 3 ç§’åå…³é—­...")
                    logger.info("========================================")
                    await asyncio.sleep(3)
                    await browser.close()
                    logger.info("æµè§ˆå™¨å·²å…³é—­ã€‚è¯·é‡æ–°è¿è¡ŒæœåŠ¡ä»¥åå°æ¨¡å¼å¯åŠ¨ã€‚")
                    return True
            else:
                if stable_count > 0 and DEBUG:
                    logger.debug("cookie çŠ¶æ€å˜åŒ–ï¼Œé‡ç½®ç¨³å®šè®¡æ•°")
                stable_count = 0

        except Exception as e:
            if DEBUG:
                logger.debug(f"æ£€æŸ¥ cookie æ—¶å‡ºé”™: {e}")
            stable_count = 0

        elapsed = (i + 1) * check_interval
        if elapsed % 30 == 0:
            logger.info(f"ç­‰å¾…ç™»å½•ä¸­... å·²ç­‰å¾… {elapsed} ç§’ï¼ˆæœ€é•¿ {max_wait_seconds} ç§’ï¼‰")

    logger.error("ç™»å½•è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰ï¼Œè¯·é‡è¯•")
    return False


async def handle_network_response(resp: Any) -> None:
    """å¤„ç†ç½‘ç»œå“åº”ï¼Œæå– JSON ä¸­çš„æ–‡æœ¬"""
    try:
        content_type = (resp.headers.get("content-type") or "").lower()
        if "application/json" not in content_type:
            return

        url = resp.url
        if not any(keyword in url for keyword in NETWORK_URL_KEYWORDS):
            return

        try:
            data = await resp.json()
        except Exception:
            return

        # ä¸´æ—¶è°ƒè¯•ï¼šæŸ¥çœ‹åŒ…å«å…³é”®è¯çš„æ¶ˆæ¯çš„å®Œæ•´æ•°æ®ç»“æ„
        texts = extract_texts_from_json(data)
        if texts and any(KEYWORD_NOTE in text or KEYWORD_TASK in text for text, _ in texts):
            if DEBUG:
                logger.debug(f"[Network] åŒ…å«å…³é”®è¯çš„æ¶ˆæ¯æ•°æ®ç»“æ„: {json.dumps(data, ensure_ascii=False, indent=2)[:1000]}...")

        for text, timestamp in texts:
            await handle_text("Network", text)

        if DEBUG and texts:
            logger.debug(f"[Network] å‘½ä¸­ {len(texts)} æ¡, URL: {url}")
    except Exception as e:
        logger.debug(f"å¤„ç†ç½‘ç»œå“åº”å¼‚å¸¸: {e}")


async def run_polling_loop(page: Page) -> None:
    """è¿è¡Œè½»é‡çº§è½®è¯¢å¾ªç¯ï¼Œä¸»è¦ä¾èµ–å®æ—¶ç›‘æ§"""
    logger.info(f"å¼€å§‹å®æ—¶ç›‘å¬...ï¼ˆå¤‡ç”¨è½®è¯¢é—´éš” {POLL_INTERVAL}sï¼‰")

    last_activity_time = time.time()
    consecutive_empty_polls = 0

    while True:
        try:
            # è½»é‡çº§å¤‡ç”¨æ‰«æï¼Œä¸»è¦ä¾èµ– MutationObserver
            # åªåœ¨å¿…è¦æ—¶è¿›è¡Œ DOM æ‰«æ
            if consecutive_empty_polls > 20:  # é•¿æ—¶é—´æ— æ´»åŠ¨æ—¶æ‰è¿›è¡Œå¤‡ç”¨æ‰«æ
                await poll_dom(page)
                consecutive_empty_polls = 0

            # ç½‘ç»œç›‘å¬ä¿æŒæ´»è·ƒ
            # brute_scrape æ”¹ä¸ºè½»é‡çº§æ£€æŸ¥
            await lightweight_check(page)

            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ´»åŠ¨
            current_stats_total = daily_stats.notes_count + daily_stats.tasks_count
            if hasattr(run_polling_loop, '_last_total'):
                if current_stats_total > run_polling_loop._last_total:
                    last_activity_time = time.time()
                    consecutive_empty_polls = 0
                    logger.info(f"âœ… æ£€æµ‹åˆ°æ–°è®°å½•ï¼æ€»è®¡: {current_stats_total}")
                else:
                    consecutive_empty_polls += 1
            else:
                run_polling_loop._last_total = current_stats_total

            run_polling_loop._last_total = current_stats_total

            # æ™ºèƒ½è½®è¯¢é—´éš”ï¼šä¸»è¦ä¾èµ–å®æ—¶ç›‘æ§ï¼Œè½®è¯¢é—´éš”å¯ä»¥æ›´é•¿
            if settings.SMART_POLLING:
                time_since_activity = time.time() - last_activity_time
                if time_since_activity < 300:  # 5åˆ†é’Ÿå†…æœ‰æ´»åŠ¨
                    poll_interval = settings.FAST_POLL_INTERVAL * 2  # å®æ—¶ç›‘æ§ä¸‹å¯ä»¥æ”¾å®½
                elif consecutive_empty_polls > 10:
                    poll_interval = settings.SLOW_POLL_INTERVAL
                else:
                    poll_interval = POLL_INTERVAL
            else:
                poll_interval = POLL_INTERVAL

            if should_log_debug("polling_info", 300):  # é™ä½æ—¥å¿—é¢‘ç‡
                logger.debug(f"è½®è¯¢é—´éš”: {poll_interval}s, ç©ºè½®è¯¢æ¬¡æ•°: {consecutive_empty_polls}, å®æ—¶ç›‘æ§æ´»è·ƒ")

        except Exception as e:
            if "has been closed" in str(e):
                logger.info("æ£€æµ‹åˆ°é¡µé¢å…³é—­ï¼Œé€€å‡ºã€‚")
                break
            if should_log_debug("polling_error", 30):
                logger.debug(f"è½®è¯¢å¼‚å¸¸: {e}")

        await asyncio.sleep(poll_interval)


async def lightweight_check(page: Page) -> None:
    """è½»é‡çº§æ£€æŸ¥ï¼Œç¡®ä¿é¡µé¢æ´»è·ƒ"""
    try:
        # ç®€å•çš„é¡µé¢æ´»è·ƒæ€§æ£€æŸ¥
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")

        # ç¡®ä¿ MutationObserver ä»åœ¨è¿è¡Œ
        is_observer_active = await page.evaluate("""
            () => {
                return window.__observerActive || false;
            }
        """)

        if not is_observer_active:
            logger.warning("âš ï¸ å®æ—¶ç›‘æ§å¯èƒ½å¤±æ•ˆï¼Œé‡æ–°æ³¨å…¥...")
            await inject_observer_to_page(page)

    except Exception as e:
        if should_log_debug("lightweight_check_error", 60):
            logger.debug(f"è½»é‡çº§æ£€æŸ¥å¼‚å¸¸: {e}")


# ========== èœå•æ å›¾æ ‡ ==========
def create_icon_image() -> Image.Image:
    """åˆ›å»ºèœå•æ å›¾æ ‡"""
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„å›¾æ ‡
    width = height = 64
    image = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(image)

    # ç»˜åˆ¶ä¸€ä¸ªç®€å•çš„ç¬”è®°æœ¬å›¾æ ‡
    draw.rectangle([10, 10, 54, 54], fill=(70, 130, 180, 255), outline=(50, 100, 150, 255), width=2)
    draw.line([20, 20, 44, 20], fill=(255, 255, 255, 255), width=2)
    draw.line([20, 28, 44, 28], fill=(255, 255, 255, 255), width=2)
    draw.line([20, 36, 44, 36], fill=(255, 255, 255, 255), width=2)
    draw.line([20, 44, 44, 44], fill=(255, 255, 255, 255), width=2)

    return image


def create_menu():
    """åˆ›å»ºèœå•æ å›¾æ ‡çš„å³é”®èœå•"""
    def show_stats():
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        stats = daily_stats.get_summary()
        last_time = ""
        if daily_stats.last_record_time:
            last_time = f"\næœ€åè®°å½•: {daily_stats.last_record_time.strftime('%H:%M:%S')}"

        send_notification("ğŸ“Š ä»Šæ—¥ç»Ÿè®¡", f"{stats}{last_time}")

    def quit_app(icon, item):
        """é€€å‡ºåº”ç”¨"""
        icon.stop()
        os._exit(0)

    return pystray.Menu(
        pystray.MenuItem("è±†åŒ…è¯­éŸ³ç¬”è®°", lambda: None, enabled=False),
        pystray.Menu.SEPARATOR,
        pystray.MenuItem("ğŸ“Š æŸ¥çœ‹ç»Ÿè®¡", show_stats),
        pystray.MenuItem("ğŸ”„ é‡ç½®ç»Ÿè®¡", lambda: daily_stats.__init__()),
        pystray.Menu.SEPARATOR,
        pystray.MenuItem("âŒ é€€å‡º", quit_app)
    )


def start_system_tray():
    """å¯åŠ¨ç³»ç»Ÿæ‰˜ç›˜å›¾æ ‡ï¼ˆmacOSéœ€è¦åœ¨ä¸»çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
    try:
        # åœ¨ macOS ä¸Šï¼Œæš‚æ—¶ç¦ç”¨ç³»ç»Ÿæ‰˜ç›˜ä»¥é¿å…å´©æºƒ
        # ç³»ç»Ÿæ‰˜ç›˜éœ€è¦åœ¨ä¸»çº¿ç¨‹ä¸­è¿è¡Œï¼Œä½†æˆ‘ä»¬çš„ä¸»çº¿ç¨‹è¢« asyncio å ç”¨
        logger.info("ç³»ç»Ÿæ‰˜ç›˜å›¾æ ‡å·²ç¦ç”¨ï¼ˆé¿å… macOS å´©æºƒï¼‰")
        logger.info("å¯ä»¥é€šè¿‡å³é”®èœå•æ å›¾æ ‡æŸ¥çœ‹ç»Ÿè®¡ï¼ˆåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼‰")
        return None

        # åŸå§‹ä»£ç ä¿ç•™ï¼Œå¾…åç»­ä¼˜åŒ–
        # icon = pystray.Icon(
        #     "doubao_voice_notes",
        #     create_icon_image(),
        #     "è±†åŒ…è¯­éŸ³ç¬”è®°",
        #     create_menu()
        # )
        #
        # # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œå›¾æ ‡
        # def run_icon():
        #     icon.run()
        #
        # icon_thread = threading.Thread(target=run_icon, daemon=True)
        # icon_thread.start()
        # logger.info("ç³»ç»Ÿæ‰˜ç›˜å›¾æ ‡å·²å¯åŠ¨")
        #
        # return icon
    except Exception as e:
        logger.error(f"å¯åŠ¨ç³»ç»Ÿæ‰˜ç›˜å›¾æ ‡å¤±è´¥: {e}")
        return None


# ========== å¯åŠ¨æ¨ªå¹… ==========
def print_startup_banner() -> None:
    """æ‰“å°å¯åŠ¨æ¨ªå¹…å’Œä½¿ç”¨è¯´æ˜"""
    print()
    print("=" * 50)
    print("  è±†åŒ…è¯­éŸ³ç¬”è®°åŠ©æ‰‹ - Obsidian åŒæ­¥å·¥å…·")
    print("=" * 50)
    print()
    print("ä½¿ç”¨æ–¹æ³•ï¼š")
    print(f"  1. è¯´ã€Œè±†åŒ…è±†åŒ…ï¼Œ{KEYWORD_NOTE}ï¼Œ<å†…å®¹>ã€è®°å½•ç¬”è®°")
    print(f"  2. è¯´ã€Œè±†åŒ…è±†åŒ…ï¼Œ{KEYWORD_TASK}ï¼Œ<å†…å®¹>ã€è®°å½•ä»»åŠ¡")
    print()
    print("æŸ¥çœ‹ç»“æœï¼š")
    print(f"  ç¬”è®°ä¿å­˜ä½ç½®: {VAULT / NOTES_DIR}")
    print(f"  ä»»åŠ¡ä¿å­˜ä½ç½®: {VAULT / TASKS_DIR}")
    print()
    print("-" * 50)
    print("å¦‚æœè¿™ä¸ªå·¥å…·å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å…³æ³¨å¼€å‘è€…ï¼š")
    print("  @WeWill_Rocky  https://x.com/WeWill_Rocky")
    print("-" * 50)
    print()


async def main() -> None:
    """ä¸»å…¥å£å‡½æ•°"""
    print_startup_banner()

    # å¯åŠ¨ç³»ç»Ÿæ‰˜ç›˜å›¾æ ‡
    tray_icon = start_system_tray()

    logger.info(f"è„šæœ¬å¯åŠ¨ï¼šHEADFUL={HEADFUL}, DEBUG={DEBUG}, CHAT_URL={CHAT_URL}")

    # æ£€æŸ¥ VAULT è·¯å¾„
    vault_path = None
    if str(VAULT).strip():
        vault_path = Path(str(VAULT)).expanduser().resolve()

    if not vault_path or not vault_path.exists():
        print("\n" + "=" * 50)
        print("  âš ï¸  Obsidian ä»“åº“è·¯å¾„æœªè®¾ç½®æˆ–ä¸å­˜åœ¨")
        print("=" * 50)
        print("\nè¯·é€‰æ‹©è®¾ç½®æ–¹å¼ï¼š")
        print("  1. è¾“å…¥ Obsidian ä»“åº“çš„ç»å¯¹è·¯å¾„")
        print("  2. æŸ¥æ‰¾å¸¸è§çš„ Obsidian ä»“åº“ä½ç½®")
        print("  3. é€€å‡ºç¨‹åº")

        choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2/3): ").strip()

        if choice == "1":
            user_path = input("\nè¯·è¾“å…¥ Obsidian ä»“åº“è·¯å¾„: ").strip()
            vault_path = Path(user_path).expanduser().resolve()

            if not vault_path.exists():
                print(f"\nâŒ è·¯å¾„ä¸å­˜åœ¨: {vault_path}")
                print("è¯·æ£€æŸ¥è·¯å¾„åé‡è¯•ã€‚")
                return

            print(f"\nâœ… è·¯å¾„éªŒè¯æˆåŠŸ: {vault_path}")
            print(f"æ­£åœ¨æ›´æ–° .env æ–‡ä»¶...")

            # æ›´æ–° .env æ–‡ä»¶
            env_file = Path(__file__).parent / ".env"
            if not env_file.exists():
                env_file.write_text("")

            env_content = env_file.read_text(encoding='utf-8')

            # æ£€æŸ¥å¹¶æ›´æ–° OBSIDIAN_VAULT
            import re
            if re.search(r'^OBSIDIAN_VAULT\s*=', env_content, re.MULTILINE):
                env_content = re.sub(
                    r'^OBSIDIAN_VAULT\s*=.*$',
                    f'OBSIDIAN_VAULT={str(vault_path)}',
                    env_content,
                    count=1,
                    flags=re.MULTILINE
                )
            else:
                env_content += f'\nOBSIDIAN_VAULT={str(vault_path)}\n'

            env_file.write_text(env_content, encoding='utf-8')
            print("âœ… .env æ–‡ä»¶å·²æ›´æ–°")
            print("\nè¯·é‡æ–°å¯åŠ¨ç¨‹åºï¼š")
            print("  python main.py")
            return

        elif choice == "2":
            print("\næ­£åœ¨æŸ¥æ‰¾å¸¸è§çš„ Obsidian ä»“åº“ä½ç½®...")

            # å¸¸è§ä½ç½®
            home = Path.home()
            common_paths = [
                home / "Documents" / "Obsidian",
                home / "Documents",
                home / "Dropbox" / "Obsidian",
                home / "OneDrive" / "Obsidian",
                home / "Library" / "Mobile Documents" / "iCloud~obsidian",
            ]

            found = False
            for base_path in common_paths:
                if not base_path.exists():
                    continue

                # æŸ¥æ‰¾ .obsidian æ–‡ä»¶å¤¹ï¼ˆObsidian ä»“åº“çš„æ ‡è¯†ï¼‰
                for vault in base_path.iterdir():
                    if vault.is_dir() and (vault / ".obsidian").exists():
                        print(f"\nâœ… æ‰¾åˆ°ä»“åº“: {vault}")
                        found = True

            if not found:
                print("\nâŒ æœªæ‰¾åˆ° Obsidian ä»“åº“")
                print("è¯·æ‰‹åŠ¨é€‰æ‹©é€‰é¡¹ 1 å¹¶è¾“å…¥è·¯å¾„ã€‚")
            return

        else:
            print("\nå·²é€€å‡ºç¨‹åºã€‚")
            return

    init_database()
    cleanup_old_records(horizon_hours=DEDUP_HOURS)

    already_logged_in = STATE_PATH.exists()

    async with async_playwright() as pw:
        browser: Browser | None = None
        try:
            browser, chosen, headless = await start_browser(pw, force_headless=already_logged_in)
            context = await browser.new_context(
                storage_state=str(STATE_PATH) if already_logged_in else None,
                user_agent=USER_AGENT
            )
            page = await context.new_page()

            page.on("response", handle_network_response)

            if not already_logged_in:
                login_url = "https://www.doubao.com/chat/login"
                logger.info(f"å·²å¯åŠ¨ï¼š{chosen} -> å‰å¾€ç™»å½•é¡µ {login_url}")
                await page.goto(login_url, timeout=120000, wait_until="domcontentloaded")
                if await wait_for_login(context, browser):
                    return
                return

            logger.info(f"å·²å¯åŠ¨ï¼š{chosen} (åå°æ¨¡å¼) -> å‰å¾€ {CHAT_URL}")
            await page.goto(CHAT_URL, timeout=120000, wait_until="domcontentloaded")

            await inject_observer_to_page(page)
            page.on("frameattached", lambda f: asyncio.create_task(inject_to_frame(f)))

            await run_polling_loop(page)
        finally:
            if browser:
                try:
                    await browser.close()
                except Exception:
                    pass

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"FATAL: {e}")